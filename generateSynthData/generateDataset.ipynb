{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb870a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import math # For radians in rose plot\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from IPython.display import display\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "from collections import Counter\n",
    "\n",
    "import random\n",
    "import subprocess\n",
    "import json # Import json to load the stats file\n",
    "import pandas as pd # Import pandas for DataFrame summary\n",
    "from utilities import plot_fault_counts, plot_histogram, plot_rose_diagram, append_param_to_cmd, normalize, plot_fault_points, count_pixels   \n",
    "from IPython.display import display\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import shutil\n",
    "\n",
    "from cigvis.plotlyplot import create_overlay, plot3D   # <-- add this\n",
    "from cigvis import colormap, config\n",
    "\n",
    "import cigvis.plotlyplot as cgp\n",
    "from cigvis.plotlyplot import create_slices, add_mask, plot3D\n",
    "from cigvis import colormap, config\n",
    "\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db5971",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94db5971",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b793181",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b40144b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0)  User picks parameters ──────────────────────────────────────────────\n",
    "mask_mode      = 0\n",
    "num_pairs      = 101\n",
    "train_split    = 100          # absolute counts\n",
    "val_split      = 1\n",
    "\n",
    "cube_size      = 128\n",
    "ricker_freq    = (50, 70)\n",
    "seismic_noise  = (0.1, 0.5)\n",
    "ricker_dt      = 0.002\n",
    "wavelet_len    = 0.2\n",
    "num_gauss      = (2, 10)\n",
    "num_faults     = (0, 4)\n",
    "max_disp       = (-50, 50)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "# CHOOSE ONE “strike_windows” line below and **comment-out** the others.\n",
    "# The text must be in quotes -- it is passed to the script verbatim.\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "# strike_windows = \"0-360\"                 # full azimuth\n",
    "# strike_windows = \"40-50\"                 # one narrow cone (≈ 45°)\n",
    "# strike_windows = \"40-50,220-230\"         # two opposite cones (≈ 45° & 225°)\n",
    "#strike_windows = \"45-135,225-315\"          # two half-circles (or \"315-45,135-225\")\n",
    "strike_windows = \"40-50,220-230,130-140,310-320\"\n",
    "# ─────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "dip            = (60, 70)\n",
    "output_format  = \"npy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ace03b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔  Using 100 training and 1 validation cubes.\n"
     ]
    }
   ],
   "source": [
    "# explicit counts\n",
    "num_train = int(train_split)\n",
    "num_val   = int(val_split)\n",
    "\n",
    "if num_train + num_val != num_pairs:\n",
    "    raise ValueError(\n",
    "        f\"ERROR: train+val ({num_train + num_val}) \"\n",
    "        f\"does not equal num_pairs ({num_pairs}).\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"✔  Using {num_train} training and {num_val} validation cubes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe2d2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────\n",
    "# 1)  ROOT directory – works in .py or notebook\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "try:                                   # for plain-.py execution\n",
    "    ROOT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:                      # Jupyter / IPython\n",
    "    ROOT_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5fe70c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ───────────────────────────────────────────────────────────────\n",
    "# 2)  Centralised output locations  (⇦ NEW)\n",
    "# ───────────────────────────────────────────────────────────────\n",
    "DATA_DIR   = os.path.join(ROOT_DIR, \"data\")        # …/generateSynthData/data\n",
    "STATS_DIR  = os.path.join(ROOT_DIR, \"statistics\")  # …/generateSynthData/statistics\n",
    "IMAGE_DIR  = os.path.join(ROOT_DIR, \"images\")      # …/generateSynthData/images\n",
    "\n",
    "# make sure they exist\n",
    "for _d in (DATA_DIR, STATS_DIR, IMAGE_DIR):\n",
    "    os.makedirs(_d, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af00bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_windows(s):\n",
    "    out = []\n",
    "    for rng in s.split(','):\n",
    "        lo, hi = map(lambda x: float(x.strip()), rng.split('-'))\n",
    "        out.append((lo, hi))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c2232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python /home/roderickperez/DS_PROJECTS/faultSeg/generateSynthData/synthDataGeneration.py --num-pairs 101 --size 128 --dt 0.002 --length 0.2 --mask-mode 0 --format npy --output-dir /home/roderickperez/DS_PROJECTS/faultSeg/generateSynthData/data --train-split 100 --val-split 1 --faults 0,4 --max-disp=-50,50 --strike 40-50,220-230,130-140,310-320 --dip 60,70 --freq 50,70 --num-gaussians 2,10 --noise 0.1,0.5 --strike-sampling equal\n",
      "\n",
      "Data split: 100 train, 1 validation.\n",
      "Output format: npy\n",
      "\n",
      "Starting data generation for 101 pairs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Cubes:   0%|          | 0/101 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# ─── call generator script ───────────────────────────────────────────────\n",
    "script    = os.path.join(ROOT_DIR, \"synthDataGeneration.py\")\n",
    "base_out  = DATA_DIR          # where the cubes will be written\n",
    "\n",
    "# wipe previous run\n",
    "for split in (\"train\", \"validation\"):\n",
    "    shutil.rmtree(os.path.join(base_out, split), ignore_errors=True)\n",
    "\n",
    "os.makedirs(base_out, exist_ok=True)\n",
    "\n",
    "cmd = [\n",
    "    \"python\", script,\n",
    "    \"--num-pairs\", str(num_pairs),\n",
    "    \"--size\",      str(cube_size),\n",
    "    \"--dt\",        str(ricker_dt),\n",
    "    \"--length\",    str(wavelet_len),\n",
    "    \"--mask-mode\", str(mask_mode),\n",
    "    \"--format\",    output_format,\n",
    "    \"--output-dir\", base_out,\n",
    "    \"--train-split\", str(train_split),\n",
    "    \"--val-split\",   str(val_split),\n",
    "\n",
    "    \"--faults\",   f\"{num_faults[0]},{num_faults[1]}\",\n",
    "    f\"--max-disp={max_disp[0]},{max_disp[1]}\",\n",
    "\n",
    "    \"--strike\",   strike_windows,\n",
    "    \"--dip\",      f\"{dip[0]},{dip[1]}\",\n",
    "    \"--freq\",     f\"{ricker_freq[0]},{ricker_freq[1]}\",\n",
    "    \"--num-gaussians\", f\"{num_gauss[0]},{num_gauss[1]}\",\n",
    "    \"--noise\",    f\"{seismic_noise[0]},{seismic_noise[1]}\",\n",
    "    \"--strike-sampling\", \"equal\" # or \"span\" where “equal” = each window chosen with equal probability; “span” = proportional to angular width.\n",
    "]\n",
    "\n",
    "print(\" \".join(cmd))\n",
    "result = subprocess.run(cmd, text=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e85e450",
   "metadata": {},
   "outputs": [],
   "source": [
    "if result.returncode == 0:\n",
    "    print(\"Data generation successful!\")\n",
    "    print(result.stdout)\n",
    "else:\n",
    "    print(\"Data generation failed.\")\n",
    "    print(result.stderr)\n",
    "\n",
    "for fname in (\"statistics_full.json\",\n",
    "              \"statistics_train.json\",\n",
    "              \"statistics_validation.json\"):\n",
    "    src = os.path.join(base_out, fname)\n",
    "    dst = os.path.join(STATS_DIR, fname)\n",
    "    if os.path.exists(src):\n",
    "        try:\n",
    "            os.replace(src, dst)          # move (overwrite if exists)\n",
    "            print(f\"Moved {fname} → {STATS_DIR}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not move {fname}: {e}\")\n",
    "    else:\n",
    "        print(f\"Warning: {fname} not found in {base_out}\")\n",
    "        \n",
    "# Data generation statistics\n",
    "stats = {\n",
    "    \"total_pairs\": num_pairs,\n",
    "    \"train_pairs\": num_train,\n",
    "    \"validation_pairs\": num_val,\n",
    "}\n",
    "\n",
    "# Save statistics to a JSON file\n",
    "stats_file_path = os.path.join(STATS_DIR, \"stats_data.json\")\n",
    "with open(stats_file_path, 'w') as f:\n",
    "    json.dump(stats, f, indent=4)\n",
    "\n",
    "print(f\"Data generation complete. Statistics saved to {stats_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185bc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 2) Check the output ────────────────────────────────────────────────\n",
    "# Check the total number of files created across all splits\n",
    "total_files_generated = 0\n",
    "for split in ['train', 'validation']:\n",
    "    seis_dir = os.path.join(base_out, split, 'seis')\n",
    "    if os.path.exists(seis_dir):\n",
    "        total_files_generated += len(os.listdir(seis_dir))\n",
    "\n",
    "if total_files_generated != num_pairs:\n",
    "    print(f\"\\nWarning: Mismatch in generated files ({total_files_generated}) and requested pairs ({num_pairs}). Check script output.\")\n",
    "else:\n",
    "    print(f\"\\nSuccessfully generated {total_files_generated} file pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b502e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append parameters that can be fixed values or ranges\n",
    "def append_param_to_cmd(cmd_list, arg_name, value):\n",
    "    if value is not None:\n",
    "        if isinstance(value, tuple):\n",
    "            cmd_list += [f\"--{arg_name}\", f\"{value[0]},{value[1]}\"]\n",
    "        else:\n",
    "            cmd_list += [f\"--{arg_name}\", str(value)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050d26d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCommand to run:\")\n",
    "print(\" \".join(cmd)) # type: ignore # Print the corrected command\n",
    "print(\"\\nRunning subprocess...\")\n",
    "\n",
    "# run and capture output\n",
    "# check=False allows inspection of returncode without raising exception immediately\n",
    "#result = subprocess.run(cmd, capture_output=True, text=True, check=False)\n",
    "print(\"=== STDOUT ===\\n\", result.stdout)\n",
    "print(\"=== STDERR ===\\n\", result.stderr)\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print(f\"Error: Script exited with return code {result.returncode}\")\n",
    "    # Optionally print more context or raise error\n",
    "    # raise subprocess.CalledProcessError(result.returncode, cmd, output=result.stdout, stderr=result.stderr)\n",
    "    # Exit this cell or notebook execution if script failed critically?\n",
    "    # For now, just print error and continue, assuming stats file might still be partially saved\n",
    "else:\n",
    "    print(\"Script finished successfully.\")\n",
    "\n",
    "# Check if the expected number of files were generated\n",
    "total_files_generated = 0\n",
    "for split in ['train', 'validation']:\n",
    "    seis_dir = os.path.join(base_out, split, 'seis')\n",
    "    if os.path.exists(seis_dir):\n",
    "        total_files_generated += len([f for f in os.listdir(seis_dir) if f.endswith((\".npy\", \".npz\", \".dat\"))])\n",
    "\n",
    "if total_files_generated != num_pairs:\n",
    "    print(f\"\\nWarning: Mismatch in generated files ({total_files_generated}) and requested pairs ({num_pairs}). Check script output.\")\n",
    "else:\n",
    "    print(f\"\\nSuccessfully generated {total_files_generated} file pairs across all splits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b287652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── 2) Load generated data and statistics ───────────────────────────────────────────────────────\n",
    "\n",
    "# Define the base output directory\n",
    "#base_out = os.path.expanduser(\"/Users/roderickperez/Documents/DS_Projects/faultSegm/faultSeg_Wu_2019_Keras/output\")\n",
    "\n",
    "# Define the splits and their expected number of files\n",
    "splits = {\n",
    "    \"train\": num_train,\n",
    "    \"validation\": num_val\n",
    "}\n",
    "\n",
    "# Check if the expected number of files were generated for each split\n",
    "for split, expected_files in splits.items():\n",
    "    seis_dir = os.path.join(base_out, split, \"seis\")\n",
    "    fault_dir = os.path.join(base_out, split, \"fault\")\n",
    "\n",
    "    if os.path.exists(seis_dir):\n",
    "        files = sorted(f for f in os.listdir(seis_dir) if f.endswith((\".npy\", \".npz\", \".dat\")))\n",
    "        n_files = len(files)\n",
    "        if n_files != expected_files:\n",
    "            print(f\"Warning: Mismatch in generated files for '{split}' split. Expected {expected_files}, found {n_files} in {seis_dir}\")\n",
    "    else:\n",
    "        print(f\"Warning: Seismic output directory not found for '{split}' split: {seis_dir}\")\n",
    "\n",
    "    if not os.path.exists(fault_dir):\n",
    "        print(f\"Warning: Fault output directory not found for '{split}' split: {fault_dir}\")\n",
    "\n",
    "# Load the statistics files\n",
    "stats_data = {}\n",
    "for split in splits.keys():\n",
    "    stats_file_path = os.path.join(STATS_DIR, f\"statistics_{split}.json\")\n",
    "    if os.path.exists(stats_file_path):\n",
    "        with open(stats_file_path, 'r') as f:\n",
    "            stats_data[split] = json.load(f)\n",
    "            print(f\"Successfully loaded statistics for '{split}' split.\")\n",
    "    else:\n",
    "        print(f\"Warning: Statistics file not found for '{split}' split: {stats_file_path}\")\n",
    "\n",
    "# Load the full statistics file\n",
    "full_stats_path = os.path.join(STATS_DIR, \"statistics_full.json\")\n",
    "if os.path.exists(full_stats_path):\n",
    "    with open(full_stats_path, 'r') as f:\n",
    "        full_stats = json.load(f)\n",
    "        print(\"Successfully loaded full statistics.\")\n",
    "else:\n",
    "    print(f\"Warning: Full statistics file not found: {full_stats_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaafc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_windows(a, windows):\n",
    "    a = a % 360.0\n",
    "    for lo, hi in windows:\n",
    "        lo, hi = lo % 360.0, hi % 360.0\n",
    "        span = (hi - lo) % 360.0 or 360.0\n",
    "        if (a - lo) % 360.0 <= span:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b05cf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Distribution of strikes across windows (full dataset) ---\n",
    "wins = parse_windows(strike_windows)   # reuse the same string you passed to the script\n",
    "\n",
    "def which_window(a):\n",
    "    for i, w in enumerate(wins):\n",
    "        if in_windows(a, [w]):         # reuse your in_windows()\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "cnt = Counter(which_window(fp['strike']) for fp in full_stats['all_fault_params'])\n",
    "total = sum(cnt.values())\n",
    "\n",
    "print(\"\\nStrike counts per window (full):\")\n",
    "for i, (lo, hi) in enumerate(wins):\n",
    "    n = cnt.get(i, 0)\n",
    "    pct = 100.0 * n / total if total else 0.0\n",
    "    print(f\"  window {i}: {lo:.1f}–{hi:.1f}° → {n} ({pct:.1f}%)\")\n",
    "print(\"  total faults counted:\", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54c9800",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in (\"train\", \"validation\"):\n",
    "    path = os.path.join(STATS_DIR, f\"statistics_{split}.json\")\n",
    "    if not os.path.exists(path):\n",
    "        continue\n",
    "    with open(path) as f:\n",
    "        s = json.load(f)\n",
    "    cnt = Counter(which_window(fp['strike']) for fp in s['all_fault_params'])\n",
    "    total = sum(cnt.values())\n",
    "    print(f\"\\n[{split}] strike counts per window:\")\n",
    "    for i, (lo, hi) in enumerate(wins):\n",
    "        n = cnt.get(i, 0)\n",
    "        pct = 100.0 * n / total if total else 0.0\n",
    "        print(f\"  window {i}: {lo:.1f}–{hi:.1f}° → {n} ({pct:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83410e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_used = \"equal\"  # or \"span\"\n",
    "if mode_used == \"equal\":\n",
    "    expected = [1/len(wins)] * len(wins)\n",
    "else:\n",
    "    spans = [((hi - lo) % 360) or 360 for lo, hi in wins]\n",
    "    s = sum(spans)\n",
    "    expected = [sp/s for sp in spans]\n",
    "print(\"\\nExpected % per window:\", [round(100*x, 1) for x in expected])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3d57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed = parse_windows(strike_windows)\n",
    "bad = [fp['strike'] for fp in full_stats['all_fault_params']\n",
    "       if not in_windows(fp['strike'], allowed)]\n",
    "print(\"outside windows:\", len(bad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c923286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all statistics: full, prediction, train, and validation\n",
    "stats_files = {\n",
    "    \"full\": os.path.join(STATS_DIR, \"statistics_full.json\"),\n",
    "    \"train\": os.path.join(STATS_DIR, \"statistics_train.json\"),\n",
    "    \"validation\": os.path.join(STATS_DIR, \"statistics_validation.json\")\n",
    "}\n",
    "\n",
    "all_stats_data = {}\n",
    "for split, path in stats_files.items():\n",
    "    if os.path.exists(path):\n",
    "        try:\n",
    "            with open(path, 'r') as f:\n",
    "                all_stats_data[split] = json.load(f)\n",
    "            print(f\"Loaded statistics for '{split}' from {path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading statistics for '{split}': {e}\")\n",
    "            all_stats_data[split] = None\n",
    "    else:\n",
    "        print(f\"Statistics file not found for '{split}': {path}\")\n",
    "        all_stats_data[split] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c8142",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ─── 3) Display Statistics and Plots for All Splits Individually ──────────────────────────────\n",
    "\n",
    "# palette for stacked plots\n",
    "normal_colour  = (0.50, 0.00, 0.50)   # purple  (Normal)\n",
    "inverse_colour = (0.00, 0.80, 0.00)   # green   (Inverse)\n",
    "    \n",
    "for split_name in ['full', 'train', 'validation']:\n",
    "    stats = all_stats_data.get(split_name)\n",
    "    print(f\"\\n--- Displaying Statistics and Plots for {split_name} data ---\")\n",
    "\n",
    "    if not stats or 'cube_level_params' not in stats or 'all_fault_params' not in stats:\n",
    "        print(f\"No statistics available for '{split_name}' split.\")\n",
    "        continue\n",
    "\n",
    "    # Extract parameters for the current split\n",
    "    cube_level_params = stats['cube_level_params']\n",
    "    all_fault_params  = stats['all_fault_params']\n",
    "\n",
    "    # Create a summary DataFrame\n",
    "    df = pd.DataFrame(cube_level_params)\n",
    "    print(\"\\nCube Generation Parameter Summary:\")\n",
    "    print(df.describe())\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # NEW ─ gather all mask cubes for pixel-class statistics\n",
    "    # ------------------------------------------------------------------\n",
    "    mask_cubes = []\n",
    "    splits_to_scan = ['train', 'validation'] if split_name == 'full' else [split_name]\n",
    "    for split_dir in splits_to_scan:\n",
    "        mdir = os.path.join(base_out, split_dir, \"fault\")\n",
    "        if not os.path.isdir(mdir):\n",
    "            continue\n",
    "        for fname in sorted(os.listdir(mdir)):\n",
    "            if not fname.endswith((\".npy\", \".dat\")):\n",
    "                continue\n",
    "            fpath = os.path.join(mdir, fname)\n",
    "            if fname.endswith(\".npy\"):\n",
    "                mask_cubes.append(np.load(fpath))\n",
    "            else:  # .dat\n",
    "                mask_cubes.append(np.fromfile(fpath, dtype=np.uint8)\n",
    "                                  .reshape((cube_size,)*3))\n",
    "\n",
    "    overall_pct, mean_pct = count_pixels(mask_cubes, mask_mode)\n",
    "\n",
    "    print(\"\\nPixel-class distribution – OVERALL (% of all voxels):\")\n",
    "    for k, v in overall_pct.items():\n",
    "        print(f\"  {k:>10}: {v:6.2f} %\")\n",
    "    print(\"Pixel-class distribution – MEAN PER CUBE:\")\n",
    "    for k, v in mean_pct.items():\n",
    "        print(f\"  {k:>10}: {v:6.2f} %\")\n",
    "\n",
    "    # --- Generate and Display Plots ---\n",
    "    if not all_fault_params:\n",
    "        print(\"\\nNo fault parameters to plot for this split.\")\n",
    "        continue\n",
    "\n",
    "    # Extract fault-specific data for plotting\n",
    "    strikes               = [f['strike'] for f in all_fault_params]\n",
    "    dips                  = [f['dip'] for f in all_fault_params]\n",
    "    displacements = [f['applied_disp_signed'] for f in all_fault_params]\n",
    "    vertical_displacements= [f['vertical_disp_component'] for f in all_fault_params]\n",
    "    noise_sigmas          = [p.get('noise_sigma')         for p in cube_level_params]\n",
    "\n",
    "    # Create a figure with a grid of subplots  (NOW 4×2)\n",
    "    fig = plt.figure(figsize=(20, 22))\n",
    "    fig.suptitle(f\"{split_name.capitalize()} Dataset Statistics\", fontsize=26)\n",
    "    gs = fig.add_gridspec(4, 2, height_ratios=[1, 1, 1, 0.7])\n",
    "\n",
    "    # Plot Fault Counts\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "\n",
    "    if mask_mode == 0:\n",
    "        # binary → one bar\n",
    "        ax1.bar(['Total'],\n",
    "                [len(all_fault_params)],\n",
    "                color=['skyblue'])\n",
    "    else:\n",
    "        # multiclass → two bars (Normal, Inverse)\n",
    "        normal_count  = sum(1 for f in all_fault_params if f['fault_type'] == 'Normal')\n",
    "        inverse_count = sum(1 for f in all_fault_params if f['fault_type'] == 'Inverse')\n",
    "        ax1.bar(['Normal', 'Inverse'],\n",
    "                [normal_count, inverse_count],\n",
    "                color=[normal_colour, inverse_colour])\n",
    "\n",
    "    ax1.set_title('Fault Type Distribution')\n",
    "    ax1.set_ylabel('Number of Faults')\n",
    "\n",
    "    # Plot Strike Rose Diagram\n",
    "    ax2 = fig.add_subplot(gs[0, 1], projection='polar')\n",
    "    if strikes:\n",
    "        if mask_mode == 1:\n",
    "            # --- separate angles\n",
    "            strikes_normal  = np.radians([f['strike'] for f in all_fault_params if f['fault_type'] == 'Normal'])\n",
    "            strikes_inverse = np.radians([f['strike'] for f in all_fault_params if f['fault_type'] == 'Inverse'])\n",
    "\n",
    "            num_bins = 18\n",
    "            bins_rad = np.linspace(0, 2*np.pi, num_bins + 1)\n",
    "            cnt_norm , _ = np.histogram(strikes_normal , bins=bins_rad)\n",
    "            cnt_inv  , _ = np.histogram(strikes_inverse, bins=bins_rad)\n",
    "\n",
    "            centres = bins_rad[:-1] + np.diff(bins_rad)/2\n",
    "            width   = np.diff(bins_rad)[0]\n",
    "\n",
    "            # first ring = Normal\n",
    "            ax2.bar(centres, cnt_norm,\n",
    "                    width=width,\n",
    "                    bottom=0.0,\n",
    "                    color=normal_colour,\n",
    "                    edgecolor='black',\n",
    "                    alpha=0.8,\n",
    "                    label='Normal')\n",
    "            # stacked on top = Inverse\n",
    "            ax2.bar(centres, cnt_inv,\n",
    "                    width=width,\n",
    "                    bottom=cnt_norm,\n",
    "                    color=inverse_colour,\n",
    "                    edgecolor='black',\n",
    "                    alpha=0.8,\n",
    "                    label='Inverse')\n",
    "\n",
    "            ax2.legend(loc='lower left', bbox_to_anchor=(1.05, 0.0))\n",
    "            ax2.set_title('Fault Strike Angles', va='bottom', y=1.1)\n",
    "            ax2.set_theta_zero_location(\"N\")  # 0° at North\n",
    "            ax2.set_theta_direction(-1)       # clockwise\n",
    "\n",
    "        else:\n",
    "            # Explicit 0–360° rose (no 180° wrapping)\n",
    "            angles = np.deg2rad(np.mod(strikes, 360.0))\n",
    "            num_bins = 18\n",
    "            bins_rad = np.linspace(0, 2*np.pi, num_bins + 1)\n",
    "            cnt, _ = np.histogram(angles, bins=bins_rad)\n",
    "\n",
    "            centres = bins_rad[:-1] + np.diff(bins_rad)/2\n",
    "            width = np.diff(bins_rad)[0]\n",
    "\n",
    "            ax2.bar(centres, cnt, width=width, bottom=0.0, edgecolor='black', alpha=0.9)\n",
    "            ax2.set_title('Fault Strike Angles', va='bottom', y=1.1)\n",
    "            ax2.set_theta_zero_location(\"N\")  # 0° at North\n",
    "            ax2.set_theta_direction(-1)       # clockwise\n",
    "\n",
    "\n",
    "    # Plot Dip Histogram\n",
    "    ax3 = fig.add_subplot(gs[1, 0])\n",
    "\n",
    "    if dips:\n",
    "        if mask_mode == 1:\n",
    "            dips_normal  = [f['dip'] for f in all_fault_params if f['fault_type'] == 'Normal']\n",
    "            dips_inverse = [f['dip'] for f in all_fault_params if f['fault_type'] == 'Inverse']\n",
    "            ax3.hist([dips_normal, dips_inverse],\n",
    "                     bins='auto',\n",
    "                     stacked=True,\n",
    "                     color=[normal_colour, inverse_colour],\n",
    "                     label=['Normal', 'Inverse'],\n",
    "                     edgecolor='black')\n",
    "            ax3.legend()\n",
    "        else:\n",
    "            plot_histogram(dips, ax=ax3, title='Fault Dip Angles',\n",
    "                           xlabel='Dip (degrees)')\n",
    "        ax3.set_title('Fault Dip Angles')\n",
    "        ax3.set_xlabel('Dip (degrees)')\n",
    "\n",
    "    # Plot Displacement Histogram\n",
    "    ax4 = fig.add_subplot(gs[1, 1])\n",
    "    if displacements:\n",
    "        if mask_mode == 1:\n",
    "            disp_normal  = [f['applied_disp_signed'] for f in all_fault_params if f['fault_type'] == 'Normal']\n",
    "            disp_inverse = [f['applied_disp_signed'] for f in all_fault_params if f['fault_type'] == 'Inverse']\n",
    "            ax4.hist([disp_normal, disp_inverse],\n",
    "                     bins='auto',\n",
    "                     stacked=True,\n",
    "                     color=[normal_colour, inverse_colour],\n",
    "                     label=['Normal', 'Inverse'],\n",
    "                     edgecolor='black')\n",
    "            ax4.legend()\n",
    "        else:\n",
    "            plot_histogram(displacements, ax=ax4, title='Applied Displacement',\n",
    "                           xlabel='Displacement (grid units)')\n",
    "        ax4.set_title('Applied Displacement')\n",
    "        ax4.set_xlabel('Displacement (grid units)')\n",
    "\n",
    "    # Plot Vertical Displacement Histogram\n",
    "    ax5 = fig.add_subplot(gs[2, 0])\n",
    "    if vertical_displacements:\n",
    "        if mask_mode == 1:\n",
    "            vdisp_normal  = [f['vertical_disp_component'] for f in all_fault_params if f['fault_type'] == 'Normal']\n",
    "            vdisp_inverse = [f['vertical_disp_component'] for f in all_fault_params if f['fault_type'] == 'Inverse']\n",
    "            ax5.hist([vdisp_normal, vdisp_inverse],\n",
    "                     bins='auto',\n",
    "                     stacked=True,\n",
    "                     color=[normal_colour, inverse_colour],\n",
    "                     label=['Normal', 'Inverse'],\n",
    "                     edgecolor='black')\n",
    "            ax5.legend()\n",
    "        else:\n",
    "            plot_histogram(vertical_displacements, ax=ax5,\n",
    "                           title='Vertical Displacement Component',\n",
    "                           xlabel='Vertical Displacement (grid units)')\n",
    "        ax5.set_title('Vertical Displacement Component')\n",
    "        ax5.set_xlabel('Vertical Displacement (grid units)')\n",
    "\n",
    "    # Plot Noise Sigma Histogram\n",
    "    ax6 = fig.add_subplot(gs[2, 1])\n",
    "    if any(n is not None for n in noise_sigmas):\n",
    "        plot_histogram([n for n in noise_sigmas if n is not None],\n",
    "                       ax=ax6, title='Seismic Noise Sigma',\n",
    "                       xlabel='Noise Sigma')\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # NEW subplot: pixel-class distribution\n",
    "    # ------------------------------------------------------------------\n",
    "    ax7 = fig.add_subplot(gs[3, :])\n",
    "    categories = list(overall_pct.keys())\n",
    "\n",
    "    if mask_mode == 0:\n",
    "        colours = ['dimgrey', 'skyblue'][:len(categories)]\n",
    "    else:\n",
    "        colour_map = {\n",
    "            'no_fault': 'dimgrey',\n",
    "            'normal'  : (0.50, 0.00, 0.50),  # purple\n",
    "            'inverse' : (0.00, 0.80, 0.00)   # green\n",
    "        }\n",
    "        colours = [colour_map[c] for c in categories]\n",
    "\n",
    "    ax7.bar(categories,\n",
    "            [overall_pct[k] for k in categories],\n",
    "            color=colours)\n",
    "    ax7.set_ylim(0, 100)\n",
    "    ax7.set_title('Pixel-Class Distribution (% of all voxels)')\n",
    "    ax7.set_ylabel('Percentage')\n",
    "    for i, k in enumerate(categories):\n",
    "        ax7.text(i, overall_pct[k] + 1, f\"{overall_pct[k]:.1f}%\", ha='center')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "    img_path = os.path.join(IMAGE_DIR, f\"{split_name}_dataset_stats.png\")\n",
    "    fig.savefig(img_path, dpi=300)\n",
    "    print(f\"Saved figure → {img_path}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13b8c5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a31794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare colormaps for sample slices\n",
    "bw_cmap             = \"gray\"\n",
    "overlay_bw_cmap     = ListedColormap([(0,0,0,0), (1,1,1,1)]) # Transparent to White\n",
    "\n",
    "mask_color_alone_cmap   = ListedColormap([\n",
    "    (0.00, 0.00, 0.00, 1.0),  # 0 → black\n",
    "    (0.50, 0.00, 0.50, 1.0),  # 1 → purple (Normal)\n",
    "    (0.00, 0.80, 0.00, 1.0)   # 2 → green (Inverse)\n",
    "])\n",
    "mask_color_overlay_cmap = ListedColormap([\n",
    "    (0,0,0,0),           # 0 → transparent\n",
    "    (0.50,0.00,0.50,1),  # 1 → purple (Normal)\n",
    "    (0.00,0.80,0.00,1)   # 2 → green (Inverse)\n",
    "])\n",
    "\n",
    "# Select colormap depending on mask_mode\n",
    "if mask_mode == 0:\n",
    "    mask_alone_cmap_slice   = bw_cmap\n",
    "    mask_overlay_cmap_slice = overlay_bw_cmap\n",
    "else:\n",
    "    mask_alone_cmap_slice   = mask_color_alone_cmap\n",
    "    mask_overlay_cmap_slice = mask_color_overlay_cmap\n",
    "\n",
    "# Transparency factor for overlays\n",
    "overlay_alpha = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee7a9f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca7b996",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6135f6",
   "metadata": {},
   "source": [
    "### 3D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d968bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalization helper\n",
    "# def normalize(v):\n",
    "#     return ((v - v.min()) / (v.max() - v.min()) * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc7f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fault plotting function\n",
    "# def plot_fault_points(fig, slice_mask, axis_index, slice_type, color, label, nx, ny, nz):\n",
    "#     if slice_type == \"inline\":\n",
    "#         ks, js = np.where(slice_mask)\n",
    "#         fig.add_trace(go.Scatter3d(\n",
    "#             x=np.full_like(ks, axis_index),\n",
    "#             y=js,\n",
    "#             z=nz - 1 - ks,\n",
    "#             mode='markers',\n",
    "#             marker=dict(color=color, size=2, opacity=1),\n",
    "#             name=label\n",
    "#         ))\n",
    "#     elif slice_type == \"crossline\":\n",
    "#         ks, is_ = np.where(slice_mask)\n",
    "#         fig.add_trace(go.Scatter3d(\n",
    "#             x=is_,\n",
    "#             y=np.full_like(is_, axis_index),\n",
    "#             z=nz - 1 - ks,\n",
    "#             mode='markers',\n",
    "#             marker=dict(color=color, size=2, opacity=1),\n",
    "#             name=label\n",
    "#         ))\n",
    "#     elif slice_type == \"timeslice\":\n",
    "#         is_, js = np.where(slice_mask)\n",
    "#         fig.add_trace(go.Scatter3d(\n",
    "#             x=is_,\n",
    "#             y=js,\n",
    "#             z=np.full_like(is_, axis_index),\n",
    "#             mode='markers',\n",
    "#             marker=dict(color=color, size=2, opacity=1),\n",
    "#             name=label\n",
    "#         ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c6f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --------------------------------------------------------------------------\n",
    "# # 3-D preview of one cube + fault-by-fault table\n",
    "# # --------------------------------------------------------------------------\n",
    "\n",
    "# def show_fault_cube(split:str, idx:int|None=None, *, seed:int|None=None):\n",
    "#     \"\"\"\n",
    "#     Visualise a random (or chosen) cube and list every individual fault.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     split : {\"train\", \"validation\"}\n",
    "#     idx   : int | None\n",
    "#         Exact cube-index (global index used for the file-name).  If *None*\n",
    "#         a cube is selected at random **but only among cubes that contain ≥ 1\n",
    "#         faults**.\n",
    "#     seed  : int | None\n",
    "#         Fixes RNG state so the *same* random cube is chosen every run.\n",
    "#     \"\"\"\n",
    "\n",
    "#     if seed is not None:\n",
    "#         random.seed(seed)\n",
    "\n",
    "#     # ------------------------------------------------------------------ paths\n",
    "#     seis_dir  = os.path.join(base_out, split, \"seis\")\n",
    "#     mask_dir  = os.path.join(base_out, split, \"fault\")\n",
    "#     stats_f   = os.path.join(STATS_DIR, f\"statistics_{split}.json\")\n",
    "\n",
    "#     if not (os.path.isdir(seis_dir) and os.path.isdir(mask_dir)):\n",
    "#         print(f\"[{split}]   output folders not found.\")\n",
    "#         return\n",
    "#     if not os.path.exists(stats_f):\n",
    "#         print(f\"[{split}]   statistics file missing: {stats_f}\")\n",
    "#         return\n",
    "\n",
    "#     # ---------------------------------------------------------------- stats –\n",
    "#     with open(stats_f, \"r\") as f:\n",
    "#         stats_json = json.load(f)\n",
    "#     # map cube-id → list[dict]  (one dict per fault)\n",
    "#     by_cube = {}\n",
    "#     for fp in stats_json[\"all_fault_params\"]:\n",
    "#         by_cube.setdefault(fp[\"cube_id\"], []).append(fp)\n",
    "\n",
    "#     # all cubes that *actually* have faults\n",
    "#     cubes_with_faults = [cid for cid, lst in by_cube.items() if len(lst) > 0]\n",
    "\n",
    "#     # ---------------------------------------------------------------- pick id\n",
    "#     if idx is None:\n",
    "#         if not cubes_with_faults:\n",
    "#             print(f\"[{split}]   no faults at all in this split.\")\n",
    "#             return\n",
    "#         idx = random.choice(cubes_with_faults)\n",
    "#     else:\n",
    "#         # sanity-check requested id\n",
    "#         if idx not in by_cube or len(by_cube[idx]) == 0:\n",
    "#             print(f\"[{split}]   cube {idx} exists but has no faults.\")\n",
    "#             return\n",
    "\n",
    "#     fname = f\"{idx}.{output_format}\"\n",
    "#     if not (os.path.exists(os.path.join(seis_dir, fname)) and\n",
    "#             os.path.exists(os.path.join(mask_dir, fname))):\n",
    "#         print(f\"[{split}]   data files for cube {idx} not found.\")\n",
    "#         return\n",
    "\n",
    "#     print(f\"[{split}] cube {idx}  →  {fname}\")\n",
    "\n",
    "#     # ---------------------------------------------------------------- load vol\n",
    "#     if fname.endswith(\".npy\"):\n",
    "#         seismic = np.load(os.path.join(seis_dir,  fname))\n",
    "#         mask    = np.load(os.path.join(mask_dir,  fname))\n",
    "#     else:  # \".dat\"\n",
    "#         shape  = (cube_size,)*3\n",
    "#         seismic = np.fromfile(os.path.join(seis_dir,  fname),\n",
    "#                               dtype=np.float32).reshape(shape)\n",
    "#         mask    = np.fromfile(os.path.join(mask_dir,  fname),\n",
    "#                               dtype=np.uint8 ).reshape(shape)\n",
    "\n",
    "#     nx, ny, nz = seismic.shape\n",
    "#     inline,  inline_m   = seismic[nx//2,:,:].T, mask[nx//2,:,:].T\n",
    "#     crossline, cross_m  = seismic[:,ny//2,:].T, mask[:,ny//2,:].T\n",
    "#     timeslice, times_m  = seismic[:,:,nz//2]  , mask[:,:,nz//2]\n",
    "\n",
    "#     # normalise slices for Surface display\n",
    "#     norm = lambda v: ((v-v.min())/(v.max()-v.min()+1e-12)*255).astype(np.uint8)\n",
    "#     inline_n, cross_n, time_n = map(norm, (inline, crossline, timeslice))\n",
    "\n",
    "#     # ---------------------------------------------------------------- figure\n",
    "#     fig = make_subplots(rows=1, cols=2,\n",
    "#                         specs=[[{'type':'scene'}, {'type':'table'}]],\n",
    "#                         column_widths=[0.75, 0.25],\n",
    "#                         horizontal_spacing=0.04)\n",
    "\n",
    "#     # seismic surfaces\n",
    "#     fig.add_trace(go.Surface(z=np.tile(np.arange(nz)[::-1], (ny,1)).T,\n",
    "#                              x=np.full((nz,ny), nx//2),\n",
    "#                              y=np.tile(np.arange(ny), (nz,1)),\n",
    "#                              surfacecolor=inline_n, colorscale=\"Gray\",\n",
    "#                              showscale=False),\n",
    "#                   row=1,col=1)\n",
    "#     fig.add_trace(go.Surface(z=np.tile(np.arange(nz)[::-1], (nx,1)).T,\n",
    "#                              x=np.tile(np.arange(nx), (nz,1)),\n",
    "#                              y=np.full((nz,nx), ny//2),\n",
    "#                              surfacecolor=cross_n, colorscale=\"Gray\",\n",
    "#                              showscale=False),\n",
    "#                   row=1,col=1)\n",
    "#     fig.add_trace(go.Surface(z=np.full((ny,nx), nz//2),\n",
    "#                              x=np.tile(np.arange(nx), (ny,1)),\n",
    "#                              y=np.tile(np.arange(ny).reshape(-1,1), (1,nx)),\n",
    "#                              surfacecolor=np.rot90(time_n, k=-1),\n",
    "#                              colorscale=\"Gray\", showscale=False),\n",
    "#                   row=1,col=1)\n",
    "\n",
    "#     # fault dots\n",
    "#     if mask_mode == 0:               # binary\n",
    "#         plot_fault_points(fig, inline_m==1 , nx//2, \"inline\"   ,\"white\",\"Inline\", nx,ny,nz)\n",
    "#         plot_fault_points(fig, cross_m==1  , ny//2, \"crossline\",\"white\",\"Cross\",  nx,ny,nz)\n",
    "#         plot_fault_points(fig, times_m==1  , nz//2, \"timeslice\",\"white\",\"T-slice\",nx,ny,nz)\n",
    "#     else:                            # multi-class\n",
    "#         colours = {1:\"green\", 2:\"purple\"}\n",
    "#         for cls,label in [(1,\"Normal\"), (2,\"Inverse\")]:\n",
    "#             plot_fault_points(fig, inline_m==cls , nx//2,\"inline\",   colours[cls],f\"Inl {label}\", nx,ny,nz)\n",
    "#             plot_fault_points(fig, cross_m==cls  , ny//2,\"crossline\",colours[cls],f\"Xl  {label}\", nx,ny,nz)\n",
    "#             plot_fault_points(fig, times_m==cls  , nz//2,\"timeslice\",colours[cls],f\"Tsl {label}\", nx,ny,nz)\n",
    "\n",
    "#     # ---------------------------------------------------------------- table\n",
    "#     faults = by_cube[idx]                      # list[dict], already non-empty\n",
    "#     dips     = [f[\"dip\"]                 for f in faults]\n",
    "#     strikes  = [f[\"strike\"]              for f in faults]\n",
    "#     slips    = [f[\"applied_disp_signed\"] for f in faults]\n",
    "#     if mask_mode == 1:\n",
    "#         ftypes = [f[\"fault_type\"] or \"?\" for f in faults]\n",
    "\n",
    "#     col_vals = [[\"#\",\n",
    "#                  \"Dip (°)\",\n",
    "#                  \"Strike (°)\",\n",
    "#                  \"Slip (vox)\"] +\n",
    "#                 ([\"Type\"] if mask_mode == 1 else []),\n",
    "#                 list(range(1, len(faults)+1)),\n",
    "#                 [f\"{d:5.1f}\" for d in dips],\n",
    "#                 [f\"{s:6.1f}\" for s in strikes],\n",
    "#                 [f\"{sl:6.1f}\"for sl in slips]]\n",
    "#     if mask_mode == 1:\n",
    "#         col_vals.append(ftypes)\n",
    "\n",
    "#     header = dict(values=col_vals[0], align=\"center\", fill_color=\"#d3d3d3\")\n",
    "#     cells  = dict(values=col_vals[1:], align=\"center\")\n",
    "#     fig.add_trace(go.Table(header=header, cells=cells), row=1, col=2)\n",
    "\n",
    "#     # ---------------------------------------------------------------- layout\n",
    "#     fig.update_layout(title=f\"{split.upper()} cube {idx}\",\n",
    "#                       scene=dict(aspectmode=\"data\",\n",
    "#                                  xaxis_visible=False,\n",
    "#                                  yaxis_visible=False,\n",
    "#                                  zaxis_visible=False),\n",
    "#                       margin=dict(l=0, r=0, t=40, b=0))\n",
    "#     display(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c50aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_fault_cube(\"train\")          # random training cube or show_fault_cube(\"train\", idx=42) # specific cube if you know the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d277238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_fault_cube(\"validation\") # random validation cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b312b049",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb2df7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5486d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- CIGVis imports ---\n",
    "\n",
    "\n",
    "# # Optional: axis & order tweaks if your data needs it\n",
    "# # config.set_order(line_first=True)           # keep default (x=inline first)\n",
    "# # config.set_axis_reversed(x=False, y=False, z=True)  # flip if your z is downwards, etc.\n",
    "\n",
    "# def view_cube_with_cigvis(base_out, stats_dir, split=\"train\", idx=None, pos=None,\n",
    "#                           clim_pct=(1, 99), mask_mode=0, output_format=\"npy\"):\n",
    "#     \"\"\"\n",
    "#     Visualize one cube with CIGVis (Plotly). Overlays binary or multi-class masks.\n",
    "#     \"\"\"\n",
    "#     seis_dir  = os.path.join(base_out, split, \"seis\")\n",
    "#     mask_dir  = os.path.join(base_out, split, \"fault\")\n",
    "#     stats_f   = os.path.join(stats_dir, f\"statistics_{split}.json\")\n",
    "\n",
    "#     # Pick a cube that actually has faults if idx not provided\n",
    "#     if idx is None and os.path.exists(stats_f):\n",
    "#         with open(stats_f, \"r\") as f:\n",
    "#             s = json.load(f)\n",
    "#         by_cube = {}\n",
    "#         for fp in s[\"all_fault_params\"]:\n",
    "#             by_cube.setdefault(fp[\"cube_id\"], []).append(fp)\n",
    "#         candidates = [cid for cid, lst in by_cube.items() if len(lst) > 0]\n",
    "#         if not candidates:\n",
    "#             raise RuntimeError(f\"No cubes with faults found in split={split}.\")\n",
    "#         idx = random.choice(candidates)\n",
    "\n",
    "#     fname = f\"{idx}.{output_format}\"\n",
    "#     seis_p = os.path.join(seis_dir, fname)\n",
    "#     mask_p = os.path.join(mask_dir, fname)\n",
    "#     if not (os.path.exists(seis_p) and os.path.exists(mask_p)):\n",
    "#         raise FileNotFoundError(f\"Missing files for cube {idx} in {split}\")\n",
    "\n",
    "#     # Load volumes (CIGVis expects (ni, nx, nt) = (inline, crossline, time))\n",
    "#     if fname.endswith(\".npy\"):\n",
    "#         seismic = np.load(seis_p).astype(np.float32)\n",
    "#         mask    = np.load(mask_p)\n",
    "#     else:  # \".dat\"\n",
    "#         # adjust dtype/shape if your writer differs\n",
    "#         shape = (seismic.shape)  # replace with your known cube_size tuple if needed\n",
    "#         seismic = np.fromfile(seis_p, np.float32).reshape(shape)\n",
    "#         mask    = np.fromfile(mask_p,  np.uint8 ).reshape(shape)\n",
    "\n",
    "#     # Pick slice positions & contrast\n",
    "#     ni, nx, nt = seismic.shape\n",
    "#     if pos is None:\n",
    "#         pos = [ni//2, nx//2, nt//2]\n",
    "#     vmin, vmax = np.percentile(seismic, clim_pct)\n",
    "\n",
    "#     # ---- discrete cmap for mask (0=background transparent; 1/2 are classes)\n",
    "#     values = sorted(np.unique(mask.astype(int)).tolist())  # e.g. [0,1] or [0,1,2]\n",
    "#     color_map = {\n",
    "#         0: (1, 1, 1),          # background (will be transparent)\n",
    "#         1: (0.50, 0.00, 0.50), # Normal (purple)\n",
    "#         2: (0.00, 0.80, 0.00), # Inverse (green)\n",
    "#     }\n",
    "#     colors   = [color_map.get(v, (1.0, 0.5, 0.0)) for v in values]\n",
    "#     fg_cmap  = colormap.custom_disc_cmap(values, colors)\n",
    "#     fg_cmap  = colormap.set_alpha_except_min(fg_cmap, 0.9)  # make value==min(values) transparent\n",
    "\n",
    "#     # ---- build overlay nodes (seismic as background, mask as foreground)\n",
    "#     nodes = create_overlay(\n",
    "#         bg_volume=seismic,\n",
    "#         fg_volume=mask.astype(int),\n",
    "#         pos=pos,\n",
    "#         bg_clim=[float(vmin), float(vmax)],\n",
    "#         fg_clim=[min(values), max(values)],\n",
    "#         bg_cmap=\"Petrel\",\n",
    "#         fg_cmap=fg_cmap,\n",
    "#         show_cbar=True,        # show legend; set cbar_type=\"fg\" to show mask colors\n",
    "#         cbar_type=\"fg\"\n",
    "#     )\n",
    "\n",
    "#     plot3D(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2fb9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# view_cube_with_cigvis(\n",
    "#     base_out=DATA_DIR,\n",
    "#     stats_dir=STATS_DIR,\n",
    "#     split=\"train\",      # or \"validation\"\n",
    "#     idx=None,           # or a specific cube id, e.g. 42\n",
    "#     mask_mode=mask_mode,\n",
    "#     output_format=output_format\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d9771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from cigvis.plotlyplot import create_slices, plot3D\n",
    "# from cigvis import colormap\n",
    "\n",
    "# # bg: seismic\n",
    "# nodes = create_slices(\n",
    "#     seismic, pos=pos,\n",
    "#     clim=[float(vmin), float(vmax)],\n",
    "#     cmap=\"Petrel\", show_cbar=True\n",
    "# )\n",
    "\n",
    "# # fg: mask (discrete cmap; make background transparent)\n",
    "# values  = sorted(np.unique(mask.astype(int)).tolist())\n",
    "# color_map = {0:(1,1,1), 1:(0.50,0.00,0.50), 2:(0.00,0.80,0.00)}\n",
    "# colors  = [color_map.get(v, (1.0,0.5,0.0)) for v in values]\n",
    "# fg_cmap = colormap.custom_disc_cmap(values, colors)\n",
    "# fg_cmap = colormap.set_alpha_except_min(fg_cmap, 0.9)\n",
    "\n",
    "# nodes += create_slices(\n",
    "#     mask.astype(int), pos=pos,\n",
    "#     clim=[min(values), max(values)],\n",
    "#     cmap=fg_cmap,\n",
    "#     interpolation=\"nearest\",   # keep classes crisp\n",
    "#     show_cbar=True\n",
    "# )\n",
    "\n",
    "# plot3D(nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d96652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CIGVis + Plotly: grayscale seismic, red mask, interactive slice sliders\n",
    "\n",
    "# import numpy as np\n",
    "# import cigvis.plotlyplot as cgp\n",
    "# from cigvis import colormap, config\n",
    "# from ipywidgets import IntSlider, HBox, VBox, interactive_output\n",
    "# from IPython.display import display\n",
    "\n",
    "# # --- your files ---\n",
    "# seis_p = \"/home/roderickperez/DS_PROJECTS/faultSeg/generateSynthData/data/train/seis/0.npy\"\n",
    "# mask_p = \"/home/roderickperez/DS_PROJECTS/faultSeg/generateSynthData/data/train/fault/0.npy\"\n",
    "\n",
    "# # --- load volumes ---\n",
    "# seismic = np.load(seis_p).astype(np.float32)\n",
    "# mask    = np.load(mask_p).astype(np.int32)\n",
    "# assert seismic.shape == mask.shape, f\"Shape mismatch: {seismic.shape} vs {mask.shape}\"\n",
    "\n",
    "# ni, nx, nt = seismic.shape\n",
    "# # If time/depth looks upside-down in your view, uncomment:\n",
    "# # config.set_axis_reversed(z=True)\n",
    "\n",
    "# # Contrast window for grayscale background\n",
    "# vmin, vmax = np.percentile(seismic, (1, 99))\n",
    "\n",
    "# # --- red discrete cmap for mask (0=transparent; all nonzero=red) ---\n",
    "# values = np.unique(mask).astype(int)\n",
    "# cols = []\n",
    "# for v in values:\n",
    "#     if v == values.min():    # assume min==0 is background\n",
    "#         cols.append((1.0, 1.0, 1.0, 0.0))  # fully transparent\n",
    "#     else:\n",
    "#         cols.append((1.0, 0.0, 0.0, 0.9))  # red with opacity\n",
    "# fg_cmap = colormap.custom_disc_cmap(values.tolist(), cols)\n",
    "# # Keep min value transparent, others ~0.9 opacity\n",
    "# fg_cmap = colormap.set_alpha_except_min(fg_cmap, 0.9)\n",
    "\n",
    "# def build_nodes(i_pos, x_pos, t_pos):\n",
    "#     pos = [i_pos, x_pos, t_pos]\n",
    "#     if hasattr(cgp, \"create_overlay\"):\n",
    "#         # Overlay mask on grayscale seismic\n",
    "#         nodes = cgp.create_overlay(\n",
    "#             bg_volume=seismic,\n",
    "#             fg_volume=mask,\n",
    "#             pos=pos,\n",
    "#             bg_clim=[float(vmin), float(vmax)],\n",
    "#             fg_clim=[int(values.min()), int(values.max())],\n",
    "#             bg_cmap=\"gray\",          # <-- grayscale seismic\n",
    "#             fg_cmap=fg_cmap,         # <-- red mask\n",
    "#             show_cbar=False          # avoid Plotly colorbar arg mismatch\n",
    "#         )\n",
    "#     else:\n",
    "#         # Fallback: stack slices (still grayscale + red)\n",
    "#         nodes = cgp.create_slices(\n",
    "#             seismic, pos=pos, clim=[float(vmin), float(vmax)],\n",
    "#             cmap=\"gray\", show_cbar=False\n",
    "#         )\n",
    "#         nodes += cgp.create_slices(\n",
    "#             mask, pos=pos,\n",
    "#             clim=[int(values.min()), int(values.max())],\n",
    "#             cmap=fg_cmap, interpolation=\"nearest\",\n",
    "#             show_cbar=False\n",
    "#         )\n",
    "#     return nodes\n",
    "\n",
    "# # --- interactive sliders (update on release) ---\n",
    "# w_i = IntSlider(min=0, max=ni-1, step=1, value=ni//2, description=\"Inline\",  continuous_update=False)\n",
    "# w_x = IntSlider(min=0, max=nx-1, step=1, value=nx//2, description=\"Xline\",  continuous_update=False)\n",
    "# w_t = IntSlider(min=0, max=nt-1, step=1, value=nt//2, description=\"Time\",    continuous_update=False)\n",
    "\n",
    "# def update(i, x, t):\n",
    "#     nodes = build_nodes(i, x, t)\n",
    "#     cgp.plot3D(nodes)  # renders the current slices\n",
    "\n",
    "# out = interactive_output(update, {\"i\": w_i, \"x\": w_x, \"t\": w_t})\n",
    "# display(VBox([HBox([w_i, w_x, w_t]), out]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dc766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipywidgets import IntSlider, Play, Button, HBox, VBox, interactive_output, jslink\n",
    "\n",
    "# # sliders (live updates while dragging)\n",
    "# w_i = IntSlider(min=0, max=ni-1, step=1, value=ni//2, description=\"Inline\",   continuous_update=True)\n",
    "# w_x = IntSlider(min=0, max=nx-1, step=1, value=nx//2, description=\"Xline\",    continuous_update=True)\n",
    "# w_t = IntSlider(min=0, max=nt-1, step=1, value=nt//2, description=\"Time\",     continuous_update=True)\n",
    "\n",
    "# # tiny helpers to step +/- with buttons\n",
    "# def step(slider, d): \n",
    "#     slider.value = max(slider.min, min(slider.max, slider.value + d))\n",
    "\n",
    "# btn_i_minus = Button(description=\"Inline −\")\n",
    "# btn_i_plus  = Button(description=\"Inline +\")\n",
    "# btn_x_minus = Button(description=\"Xline −\")\n",
    "# btn_x_plus  = Button(description=\"Xline +\")\n",
    "# btn_t_minus = Button(description=\"Time −\")\n",
    "# btn_t_plus  = Button(description=\"Time +\")\n",
    "\n",
    "# btn_i_minus.on_click(lambda _: step(w_i, -1))\n",
    "# btn_i_plus .on_click(lambda _: step(w_i, +1))\n",
    "# btn_x_minus.on_click(lambda _: step(w_x, -1))\n",
    "# btn_x_plus .on_click(lambda _: step(w_x, +1))\n",
    "# btn_t_minus.on_click(lambda _: step(w_t, -1))\n",
    "# btn_t_plus .on_click(lambda _: step(w_t, +1))\n",
    "\n",
    "# # Play widget to auto-scan time\n",
    "# play = Play(interval=60, value=w_t.value, min=w_t.min, max=w_t.max, step=1, description=\"▶\")\n",
    "# jslink((play, 'value'), (w_t, 'value'))  # link playhead to time slider\n",
    "\n",
    "# def update(i, x, t):\n",
    "#     nodes = build_nodes(i, x, t)  # your function from earlier\n",
    "#     cgp.plot3D(nodes)\n",
    "\n",
    "# out = interactive_output(update, {\"i\": w_i, \"x\": w_x, \"t\": w_t})\n",
    "# display(VBox([\n",
    "#     HBox([w_i, btn_i_minus, btn_i_plus]),\n",
    "#     HBox([w_x, btn_x_minus, btn_x_plus]),\n",
    "#     HBox([w_t, btn_t_minus, btn_t_plus, play]),\n",
    "#     out\n",
    "# ]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee70a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CIGVis viewer (grayscale seismic + red mask, with sliders) ---\n",
    "import os, json, random\n",
    "import numpy as np\n",
    "import cigvis.plotlyplot as cgp\n",
    "from cigvis import colormap, config\n",
    "from ipywidgets import IntSlider, Play, Button, HBox, VBox, interactive_output, jslink\n",
    "from IPython.display import display\n",
    "\n",
    "BASE_OUT  = DATA_DIR    # already defined earlier\n",
    "STATS_DIR = STATS_DIR   # already defined earlier\n",
    "FMT       = output_format  # \"npy\" or \"dat\"\n",
    "\n",
    "def choose_idx_with_faults(split=\"train\"):\n",
    "    stats_f = os.path.join(STATS_DIR, f\"statistics_{split}.json\")\n",
    "    with open(stats_f, \"r\") as f:\n",
    "        s = json.load(f)\n",
    "    by_cube = {}\n",
    "    for fp in s[\"all_fault_params\"]:\n",
    "        by_cube.setdefault(fp[\"cube_id\"], []).append(fp)\n",
    "    cands = [cid for cid, lst in by_cube.items() if lst]\n",
    "    if not cands:\n",
    "        raise RuntimeError(f\"No cubes with faults in split={split}\")\n",
    "    return random.choice(cands)\n",
    "\n",
    "def load_volumes(split, idx, fmt=FMT, cube_size=(cube_size,)*3):\n",
    "    fn = f\"{idx}.{fmt}\"\n",
    "    seis_p = os.path.join(BASE_OUT, split, \"seis\", fn)\n",
    "    mask_p = os.path.join(BASE_OUT, split, \"fault\", fn)\n",
    "    if not (os.path.exists(seis_p) and os.path.exists(mask_p)):\n",
    "        raise FileNotFoundError(f\"Missing files for cube {idx} in {split}\")\n",
    "    if fmt == \"npy\":\n",
    "        seismic = np.load(seis_p).astype(np.float32)\n",
    "        mask    = np.load(mask_p).astype(np.int32)\n",
    "    else:\n",
    "        seismic = np.fromfile(seis_p, np.float32).reshape(cube_size)\n",
    "        mask    = np.fromfile(mask_p,  np.uint8 ).reshape(cube_size).astype(np.int32)\n",
    "    return seismic, mask\n",
    "\n",
    "# Pick a cube that actually has faults\n",
    "split   = \"train\"            # or \"validation\"\n",
    "idx     = choose_idx_with_faults(split)\n",
    "seismic, mask = load_volumes(split, idx)\n",
    "\n",
    "# Contrast & mask mapping\n",
    "vmin, vmax = np.percentile(seismic, (1, 99))\n",
    "mask_bin   = (mask > 0).astype(np.int32)     # any nonzero → 1 (single red class)\n",
    "values     = [0, 1]\n",
    "cols       = [(1.0, 1.0, 1.0, 0.0), (1.0, 0.0, 0.0, 0.9)]  # 0 transparent, 1 red\n",
    "fg_cmap    = colormap.custom_disc_cmap(values, cols)\n",
    "fg_cmap    = colormap.set_alpha_except_min(fg_cmap, 0.9)\n",
    "\n",
    "# Optional: flip Z if your time/depth is downwards\n",
    "# config.set_axis_reversed(z=True)\n",
    "\n",
    "ni, nx, nt = seismic.shape\n",
    "def build_nodes(i, x, t):\n",
    "    pos = [int(i), int(x), int(t)]\n",
    "    if hasattr(cgp, \"create_overlay\"):\n",
    "        nodes = cgp.create_overlay(\n",
    "            bg_volume=seismic,\n",
    "            fg_volume=mask_bin,\n",
    "            pos=pos,\n",
    "            bg_clim=[float(vmin), float(vmax)],\n",
    "            fg_clim=[0, 1],\n",
    "            bg_cmap=\"gray\",          # grayscale seismic\n",
    "            fg_cmap=fg_cmap,         # red mask\n",
    "            show_cbar=False\n",
    "        )\n",
    "    else:\n",
    "        # Fallback: stacked slices\n",
    "        nodes  = cgp.create_slices(seismic, pos=pos, clim=[float(vmin), float(vmax)],\n",
    "                                   cmap=\"gray\", show_cbar=False)\n",
    "        nodes += cgp.create_slices(mask_bin, pos=pos, clim=[0, 1],\n",
    "                                   cmap=fg_cmap, interpolation=\"nearest\", show_cbar=False)\n",
    "    return nodes\n",
    "\n",
    "# --- Sliders + small step buttons + time play ---\n",
    "w_i = IntSlider(min=0, max=ni-1, step=1, value=ni//2, description=\"Inline\",   continuous_update=True)\n",
    "w_x = IntSlider(min=0, max=nx-1, step=1, value=nx//2, description=\"Xline\",    continuous_update=True)\n",
    "w_t = IntSlider(min=0, max=nt-1, step=1, value=nt//2, description=\"Time\",     continuous_update=True)\n",
    "\n",
    "def step(slider, d):\n",
    "    slider.value = max(slider.min, min(slider.max, slider.value + d))\n",
    "\n",
    "btn_i_minus = Button(description=\"Inline −\"); btn_i_minus.on_click(lambda _: step(w_i, -1))\n",
    "btn_i_plus  = Button(description=\"Inline +\"); btn_i_plus .on_click(lambda _: step(w_i, +1))\n",
    "btn_x_minus = Button(description=\"Xline −\");  btn_x_minus.on_click(lambda _: step(w_x, -1))\n",
    "btn_x_plus  = Button(description=\"Xline +\");  btn_x_plus .on_click(lambda _: step(w_x, +1))\n",
    "btn_t_minus = Button(description=\"Time −\");   btn_t_minus.on_click(lambda _: step(w_t, -1))\n",
    "btn_t_plus  = Button(description=\"Time +\");   btn_t_plus .on_click(lambda _: step(w_t, +1))\n",
    "\n",
    "play = Play(interval=60, value=w_t.value, min=w_t.min, max=w_t.max, step=1, description=\"▶\")\n",
    "jslink((play, 'value'), (w_t, 'value'))\n",
    "\n",
    "def update(i, x, t):\n",
    "    nodes = build_nodes(i, x, t)\n",
    "    cgp.plot3D(nodes)\n",
    "\n",
    "out = interactive_output(update, {\"i\": w_i, \"x\": w_x, \"t\": w_t})\n",
    "display(VBox([\n",
    "    HBox([w_i, btn_i_minus, btn_i_plus]),\n",
    "    HBox([w_x, btn_x_minus, btn_x_plus]),\n",
    "    HBox([w_t, btn_t_minus, btn_t_plus, play]),\n",
    "    out\n",
    "]))\n",
    "print(f\"Viewing split='{split}', cube id={idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2833b54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "faultseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
